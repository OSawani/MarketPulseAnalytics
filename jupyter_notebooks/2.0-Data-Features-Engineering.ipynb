{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, html, dcc, Input, Output\n",
    "import plotly.io as pio\n",
    "import dash_bootstrap_components as dbc\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "# from sklearn.metrics import mean_squared_error# deprecated\n",
    "from sklearn.metrics import root_mean_squared_error,make_scorer# alternative\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from datetime import timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Insider Trading Data:**\n",
    "    - Total Rows: 1,322,820\n",
    "    - Unique Symbols: 7,877\n",
    "\n",
    "- **Stock Prices Data:**\n",
    "    - Total Rows: 5,442,556\n",
    "    - Unique Symbols: 7,163\n",
    "\n",
    "- **Merged Data:**\n",
    "    - Total Rows: 978,647\n",
    "    - Unique Symbols: 4,450\n",
    "\n",
    "- **Working Business Days (2014-2017):** 1,043\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Columns Description\n",
    "\n",
    "- **Insider Trading Data Columns:**\n",
    "    - `TRANS_DATE`, `TRANS_SHARES`, `TRANS_PRICEPERSHARE`, `SHRS_OWND_FOLWNG_TRANS`\n",
    "    - `EQUITY_SWAP_INVOLVED`, `TRANS_TIMELINESS`, `TRANS_ACQUIRED_DISP_CD`, `DIRECT_INDIRECT_OWNERSHIP`\n",
    "    - `FILING_DATE`, `PERIOD_OF_REPORT`\n",
    "    - `ISSUERTRADINGSYMBOL` (same as `SYMBOL` in stock prices data)\n",
    "    - `RPTOWNER_RELATIONSHIP` (e.g., ten percent owner, director, officer, etc.)\n",
    "\n",
    "- **Stock Prices Data Columns:**\n",
    "    - `Date`, `Open`, `High`, `Low`, `Close`, `Volume`, `SYMBOL`\n",
    "\n",
    "## Scratchpad\n",
    "\n",
    "- The columns such as `TRANS_DATE`, `TRANS_SHARES`, `TRANS_PRICEPERSHARE`, and `SHRS_OWND_FOLWNG_TRANS` can be used to relate insider trading transactions to stock prices.\n",
    "- Flags like `EQUITY_SWAP_INVOLVED`, `TRANS_TIMELINESS`, `TRANS_ACQUIRED_DISP_CD`, and `DIRECT_INDIRECT_OWNERSHIP` provide additional context for each transaction.\n",
    "- `FILING_DATE` and `PERIOD_OF_REPORT` can help in processing and predicting stock prices in relation to insider trading data.\n",
    "- `RPTOWNER_RELATIONSHIP` can be used to analyze the effect of a person's role on insider trading transactions and their impact on stock prices.\n",
    "- The insider trading data is naturally less than the stock prices data as not all companies have insider trading data.\n",
    "- The merged data could be useful for predicting stock prices based on insider trading data, showing a direct daily relationship between insider trading data and stock prices.\n",
    "- There will be many more data points in the stock prices that have no corresponding insider trading data, indicating an indirect relationship between insider trading data and stock prices.\n",
    "- In our plot, we can first plot all stock prices and then color-code the points that have insider trading data versus those that don't.\n",
    "- Some insiders stock price is zero! we need to handle that somehow.\n",
    "- Predicting LOW, HIGH, CLOSE, Open is actually already great with regression and without using insiders trading.\n",
    "- VOLUME predictions is a bit tricky and might be improved with insider trading data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering/ Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder paths\n",
    "insider_transactions_path = os.path.join('..', 'data', 'interim', 'insider_transactions','interim_insider_transactions.csv')\n",
    "stock_prices_path = os.path.join('..', 'data', 'interim', 'stock_prices','interim_stock_prices.csv')\n",
    "merged_path = os.path.join('..', 'data', 'interim', 'merged_insider_transactions_stock_prices','interim_merged_insider_transactions_stock_prices.csv')\n",
    "df_insider_transactions = pd.read_csv(insider_transactions_path)\n",
    "df_stock_prices = pd.read_csv(stock_prices_path)\n",
    "df_merged = pd.read_csv(merged_path)\n",
    "# --------------------------------------------\n",
    "def clean_data(df):\n",
    "    df['RPTOWNER_RELATIONSHIP'] = df['RPTOWNER_RELATIONSHIP'].apply(lambda x: 'TenPercentOwner' if 'TenPercentOwner' in x else x)\n",
    "    df['RPTOWNER_RELATIONSHIP'] = df['RPTOWNER_RELATIONSHIP'].apply(lambda x: 'Director' if 'Director' in x else x)\n",
    "    df['RPTOWNER_RELATIONSHIP'] = df['RPTOWNER_RELATIONSHIP'].apply(lambda x: 'Officer' if 'Officer' in x else x)\n",
    "    return df\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the merged dataframe\n",
    "df_merged = pd.read_csv(merged_path)\n",
    "df_merged = clean_data(df_merged)\n",
    "df_merged['TRANS_DATE'] = pd.to_datetime(df_merged['TRANS_DATE'])\n",
    "# sort the dataframe by TRANS_DATE\n",
    "df_merged = df_merged.sort_values(['TRANS_DATE'])\n",
    "df_merged['TransactionValue'] = df_merged['TRANS_PRICEPERSHARE'] * df_merged['TRANS_SHARES']\n",
    "# Precompute a set of (Date, Symbol) tuples for faster lookup\n",
    "df_merged['Date_Symbol'] = df_merged['TRANS_DATE'].dt.strftime('%Y-%m-%d') + '_' + df_merged['SYMBOL']\n",
    "date_symbol_set = set(df_merged['Date_Symbol'])\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the insider transactions dataframe\n",
    "df_insider_transactions = pd.read_csv(insider_transactions_path)\n",
    "df_insider_transactions = clean_data(df_insider_transactions)\n",
    "df_insider_transactions['TRANS_DATE'] = pd.to_datetime(df_insider_transactions['TRANS_DATE'])\n",
    "# sort the dataframe by TRANS_DATE\n",
    "df_insider_transactions = df_insider_transactions.sort_values(['TRANS_DATE'])\n",
    "df_insider_transactions['TransactionValue'] = df_insider_transactions['TRANS_PRICEPERSHARE'] * df_insider_transactions['TRANS_SHARES']\n",
    "# Vectorized check for 'Exists in Stock Prices'\n",
    "df_insider_transactions['Date_Symbol'] = df_insider_transactions['TRANS_DATE'].dt.strftime('%Y-%m-%d') + '_' + df_insider_transactions['ISSUERTRADINGSYMBOL']\n",
    "df_insider_transactions['Exists in Stock Prices'] = df_insider_transactions['Date_Symbol'].isin(date_symbol_set)\n",
    "# rename ISSUERTRADINGSYMBOL to SYMBOL\n",
    "df_insider_transactions.rename(columns={'ISSUERTRADINGSYMBOL': 'SYMBOL'}, inplace=True)\n",
    "# Add lag features for 1, 3, and 7 days for TRANS_SHARES, TRANS_PRICEPERSHARE, and TransactionValue\n",
    "# not actual last date 7 days ago but rather,last 7 data points\n",
    "# Add lag features for 7 and 21 days for TRANS_SHARES and TRANS_PRICEPERSHARE per SYMBOL\n",
    "lags = [7, 21]\n",
    "for lag in lags:\n",
    "    df_insider_transactions[f'TRANS_SHARES_Lag{lag}'] = df_insider_transactions.groupby('SYMBOL')['TRANS_SHARES'].shift(lag)\n",
    "    df_insider_transactions[f'TRANS_PRICEPERSHARE_Lag{lag}'] = df_insider_transactions.groupby('SYMBOL')['TRANS_PRICEPERSHARE'].shift(lag)\n",
    "# Add moving average features for 7-day and 21-day periods for TransactionValue per SYMBOL\n",
    "moving_averages = [7, 21]\n",
    "for window in moving_averages:\n",
    "    df_insider_transactions[f'TransactionValue_MA{window}'] = (\n",
    "        df_insider_transactions.groupby('SYMBOL')['TransactionValue']\n",
    "        .transform(lambda x: x.rolling(window=window, min_periods=1).mean())\n",
    "    )\n",
    "# ------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean the stock prices dataframe\n",
    "df_stock_prices = pd.read_csv(stock_prices_path)\n",
    "df_stock_prices.loc[df_stock_prices['Low'] < 0, 'Low'] = df_stock_prices.loc[df_stock_prices['Low'] < 0, 'Open']\n",
    "df_stock_prices['Date'] = pd.to_datetime(df_stock_prices['Date'])\n",
    "df_stock_prices = df_stock_prices.sort_values(['Date'])\n",
    "df_stock_prices['DateNumeric'] = (df_stock_prices['Date'] - df_stock_prices['Date'].min()).dt.days\n",
    "df_stock_prices['MeanTotalValue'] = df_stock_prices['Volume'] * df_stock_prices[['Low', 'High', 'Open', 'Close']].mean(axis=1)\n",
    "# Add lag features for 1, 3, and 7 days for Open, Close, High, Low, and Volume\n",
    "# Add lag features for 1, 3, and 7 days for Open, Close, High, Low, and Volume per symbol\n",
    "lags = [1, 3, 7]\n",
    "grouped = df_stock_prices.groupby('SYMBOL')\n",
    "for lag in lags:\n",
    "    df_stock_prices[f'Open_Lag{lag}'] = grouped['Open'].shift(lag)\n",
    "    df_stock_prices[f'Close_Lag{lag}'] = grouped['Close'].shift(lag)\n",
    "    df_stock_prices[f'High_Lag{lag}'] = grouped['High'].shift(lag)\n",
    "    df_stock_prices[f'Low_Lag{lag}'] = grouped['Low'].shift(lag)\n",
    "    df_stock_prices[f'Volume_Lag{lag}'] = grouped['Volume'].shift(lag)\n",
    "# Add moving average features for 3-day and 7-day periods for Open, Close, High, Low, and Volume\n",
    "# Add moving average features for 3-day and 7-day periods for Open, Close, High, Low, Volume, and MeanTotalValue per symbol\n",
    "moving_averages = [3, 7]\n",
    "for window in moving_averages:\n",
    "    df_stock_prices[f'Open_MA{window}'] = grouped['Open'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_stock_prices[f'Close_MA{window}'] = grouped['Close'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_stock_prices[f'High_MA{window}'] = grouped['High'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_stock_prices[f'Low_MA{window}'] = grouped['Low'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_stock_prices[f'Volume_MA{window}'] = grouped['Volume'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "    df_stock_prices[f'MeanTotalValue_MA{window}'] = grouped['MeanTotalValue'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Vectorized check for 'Exists in Insiders' ( much faster search than using .apply() )\n",
    "df_stock_prices['Date_Symbol'] = df_stock_prices['Date'].dt.strftime('%Y-%m-%d') + '_' + df_stock_prices['SYMBOL']\n",
    "df_stock_prices['Exists in Insiders'] = df_stock_prices['Date_Symbol'].isin(date_symbol_set)# date_symbol_set set that contains common dates && symbols in both insider_transactions and stock_prices\n",
    "\n",
    "\n",
    "# Perform merge_asof with a 7-day tolerance\n",
    "df_stock_prices = pd.merge_asof(\n",
    "    df_stock_prices,\n",
    "    df_merged[['TRANS_DATE', 'SYMBOL']],\n",
    "    by='SYMBOL',\n",
    "    left_on='Date',\n",
    "    right_on='TRANS_DATE',\n",
    "    direction='backward',\n",
    "    tolerance=pd.Timedelta('7D')\n",
    ")\n",
    "# Create flag column\n",
    "df_stock_prices['InsiderTransactionInLast7Days'] = df_stock_prices['TRANS_DATE'].notnull()\n",
    "# Drop 'TRANS_DATE' column if not needed\n",
    "df_stock_prices = df_stock_prices.drop(columns=['TRANS_DATE'])\n",
    "# we do same thing for 21 days\n",
    "df_stock_prices = pd.merge_asof(\n",
    "    df_stock_prices,\n",
    "    df_merged[['TRANS_DATE', 'SYMBOL']],\n",
    "    by='SYMBOL',\n",
    "    left_on='Date',\n",
    "    right_on='TRANS_DATE',\n",
    "    direction='backward',\n",
    "    tolerance=pd.Timedelta('21D')\n",
    ")\n",
    "# Create flag column\n",
    "df_stock_prices['InsiderTransactionInLast21Days'] = df_stock_prices['TRANS_DATE'].notnull()\n",
    "# Drop 'TRANS_DATE' column\n",
    "df_stock_prices = df_stock_prices.drop(columns=['TRANS_DATE'])\n",
    "# find the row with same date and symbol in df_merged or the closest date \n",
    "# once the date is found, we use df_insider_transactions to get:\n",
    "# and add the TransactionValue_MA7, TRANS_PRICEPERSHARE_Lag7,TRANS_SHARES_Lag7, TransactionValue_MA21, TRANS_PRICEPERSHARE_Lag21,TRANS_SHARES_Lag21\n",
    "# Prepare df_insider_transactions with the required columns\n",
    "insider_cols = [\n",
    "    'SYMBOL',\n",
    "    'TRANS_DATE',\n",
    "    'TransactionValue_MA7', 'TRANS_PRICEPERSHARE_Lag7', 'TRANS_SHARES_Lag7',\n",
    "    'TransactionValue_MA21', 'TRANS_PRICEPERSHARE_Lag21', 'TRANS_SHARES_Lag21'\n",
    "]\n",
    "# Perform merge_asof to get the nearest prior insider transaction for each stock\n",
    "df_stock_prices = pd.merge_asof(\n",
    "    df_stock_prices,\n",
    "    df_insider_transactions[insider_cols],\n",
    "    left_on='Date',\n",
    "    right_on='TRANS_DATE',\n",
    "    by='SYMBOL',\n",
    "    direction='backward'\n",
    ")\n",
    "# Prefix the insider columns and drop the originals\n",
    "insider_columns = [\n",
    "    'TransactionValue_MA7', 'TRANS_PRICEPERSHARE_Lag7', 'TRANS_SHARES_Lag7',\n",
    "    'TransactionValue_MA21', 'TRANS_PRICEPERSHARE_Lag21', 'TRANS_SHARES_Lag21'\n",
    "]\n",
    "for col in insider_columns:\n",
    "    df_stock_prices['insider_' + col] = df_stock_prices[col]\n",
    "    df_stock_prices.drop(columns=col, inplace=True)\n",
    "# Drop 'TRANS_DATE' \n",
    "df_stock_prices.drop(columns='TRANS_DATE', inplace=True)\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save in CSV 'processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now want to save the dataframes to csv files in the path ../data/processed\n",
    "# df_insider_transactions in the subfolder insider_transactions\n",
    "# df_stock_prices in the subfolder stock_prices\n",
    "# df_merged in the subfolder merged_insider_transactions_stock_prices\n",
    "# Create the folder paths if they do not exist\n",
    "insider_transactions_folder = os.path.join('..', 'data', 'processed', 'insider_transactions')\n",
    "stock_prices_folder = os.path.join('..', 'data', 'processed', 'stock_prices')\n",
    "merged_folder = os.path.join('..', 'data', 'processed', 'merged_insider_transactions_stock_prices')\n",
    "os.makedirs(insider_transactions_folder, exist_ok=True)\n",
    "os.makedirs(stock_prices_folder, exist_ok=True)\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "# Save the dataframes to csv files\n",
    "df_insider_transactions.to_csv(os.path.join(insider_transactions_folder, 'processed_insider_transactions.csv'), index=False)\n",
    "df_stock_prices.to_csv(os.path.join(stock_prices_folder, 'processed_stock_prices.csv'), index=False)\n",
    "df_merged.to_csv(os.path.join(merged_folder, 'processed_merged_insider_transactions_stock_prices.csv'), index=False)\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
